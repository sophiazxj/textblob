{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob: Simplified Text Processing\n",
    "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "**TextBlob** stands on the giant shoulders of **NLTK** and **pattern**, and plays nicely with both.\n",
    "\n",
    "### Features\n",
    "* Noun phrase extraction\n",
    "* Part-of-speech tagging\n",
    "* Sentiment analysis\n",
    "* Classification (Naive Bayes, Decision Tree)\n",
    "* Language translation and detection powered by Google Translate\n",
    "* Tokenization (splitting text into words and sentences)\n",
    "* Word and phrase frequencies\n",
    "* Parsing\n",
    "* n-grams\n",
    "* Word inflection (pluralization and singularization) and lemmatization\n",
    "* Spelling correction\n",
    "* Add new models or languages through extensions\n",
    "* WordNet integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('titular', 'JJ'),\n",
       " ('threat', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('The', 'DT'),\n",
       " ('Blob', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('always', 'RB'),\n",
       " ('struck', 'VBN'),\n",
       " ('me', 'PRP'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('ultimate', 'JJ'),\n",
       " ('movie', 'NN'),\n",
       " ('monster', 'NN'),\n",
       " ('an', 'DT'),\n",
       " ('insatiably', 'RB'),\n",
       " ('hungry', 'JJ'),\n",
       " ('amoeba-like', 'JJ'),\n",
       " ('mass', 'NN'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('penetrate', 'VB'),\n",
       " ('virtually', 'RB'),\n",
       " ('any', 'DT'),\n",
       " ('safeguard', 'NN'),\n",
       " ('capable', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('doomed', 'JJ'),\n",
       " ('doctor', 'NN'),\n",
       " ('chillingly', 'RB'),\n",
       " ('describes', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('assimilating', 'VBG'),\n",
       " ('flesh', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('contact', 'NN'),\n",
       " ('Snide', 'JJ'),\n",
       " ('comparisons', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('gelatin', 'VB'),\n",
       " ('be', 'VB'),\n",
       " ('damned', 'VBN'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('concept', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('devastating', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('potential', 'JJ'),\n",
       " ('consequences', 'NNS'),\n",
       " ('not', 'RB'),\n",
       " ('unlike', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('grey', 'NN'),\n",
       " ('goo', 'NN'),\n",
       " ('scenario', 'NN'),\n",
       " ('proposed', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('technological', 'JJ'),\n",
       " ('theorists', 'NNS'),\n",
       " ('fearful', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('run', 'NN'),\n",
       " ('rampant', 'NN')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a textblob\n",
    "blob = TextBlob(text)\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['titular threat', 'blob', 'ultimate movie monster', 'amoeba-like mass', 'snide', 'potential consequences', 'grey goo scenario', 'technological theorists fearful', 'artificial intelligence run rampant'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06000000000000001\n",
      "-0.34166666666666673\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Blob的名义威胁一直让我成为最终的电影\n",
       "怪物：一个不能容忍的饥饿，阿米巴样的物质能够穿透\n",
       "几乎所有的保障措施，都能成为一个悲观的医生\n",
       "描述它 - “同化接触肉体。\n",
       "Snide比较明胶是该死的，这是一个最多的概念\n",
       "破坏性的潜在后果，不像灰色的情况\n",
       "技术理论家提出的可怕的提议\n",
       "人工智能猖獗。\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.translate(to = 'zh-CN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language Support for the Phrase-Based Machine Translation Model**\n",
    "\n",
    "Language|ISO-639-1 Code\n",
    "--------|--------------\n",
    "Afrikaans|af\n",
    "Albanian|sq\n",
    "Amharic|am\n",
    "Arabic|ar\n",
    "Armenian|hy\n",
    "Azeerbaijani|az\n",
    "Basque|eu\n",
    "Belarusian|be\n",
    "Bengali|bn\n",
    "Bosnian|bs\n",
    "Bulgarian|bg\n",
    "Catalan|ca\n",
    "Cebuano|ceb (ISO-639-2)\n",
    "Chinese (Simplified)|zh-CN (BCP-47)\n",
    "Chinese (Traditional)|zh-TW (BCP-47)\n",
    "Corsican|co\n",
    "Croatian|hr\n",
    "Czech|cs\n",
    "Danish|da\n",
    "Dutch|nl\n",
    "English|en\n",
    "Esperanto|eo\n",
    "Estonian|et\n",
    "Finnish|fi\n",
    "French|fr\n",
    "Frisian|fy\n",
    "Galician|gl\n",
    "Georgian|ka\n",
    "German|de\n",
    "Greek|el\n",
    "Gujarati|gu\n",
    "Haitian Creole|ht\n",
    "Hausa|ha\n",
    "Hawaiian|haw (ISO-639-2)\n",
    "Hebrew|iw\n",
    "Hindi|hi\n",
    "Hmong|hmn (ISO-639-2)\n",
    "Hungarian|hu\n",
    "Icelandic|is\n",
    "Igbo|ig\n",
    "Indonesian|id\n",
    "Irish|ga\n",
    "Italian|it\n",
    "Japanese|ja\n",
    "Javanese|jw\n",
    "Kannada|kn\n",
    "Kazakh|kk\n",
    "Khmer|km\n",
    "Korean|ko\n",
    "Kurdish|ku\n",
    "Kyrgyz|ky\n",
    "Lao|lo\n",
    "Latin|la\n",
    "Latvian|lv\n",
    "Lithuanian|lt\n",
    "Luxembourgish|lb\n",
    "Macedonian|mk\n",
    "Malagasy|mg\n",
    "Malay|ms\n",
    "Malayalam|ml\n",
    "Maltese|mt\n",
    "Maori|mi\n",
    "Marathi|mr\n",
    "Mongolian|mn\n",
    "Myanmar (Burmese)|my\n",
    "Nepali|ne\n",
    "Norwegian|no\n",
    "Nyanja (Chichewa)|ny\n",
    "Pashto|ps\n",
    "Persian|fa\n",
    "Polish|pl\n",
    "Portuguese (Portugal, Brazil)|pt\n",
    "Punjabi|pa\n",
    "Romanian|ro\n",
    "Russian|ru\n",
    "Samoan|sm\n",
    "Scots Gaelic|gd\n",
    "Serbian|sr\n",
    "Sesotho|st\n",
    "Shona|sn\n",
    "Sindhi|sd\n",
    "Sinhala (Sinhalese)|si\n",
    "Slovak|sk\n",
    "Slovenian|sl\n",
    "Somali|so\n",
    "Spanish|es\n",
    "Sundanese|su\n",
    "Swahili|sw\n",
    "Swedish|sv\n",
    "Tagalog (Filipino)|tl\n",
    "Tajik|tg\n",
    "Tamil|ta\n",
    "Telugu|te\n",
    "Thai|th\n",
    "Turkish|tr\n",
    "Ukrainian|uk\n",
    "Urdu|ur\n",
    "Uzbek|uz\n",
    "Vietnamese|vi\n",
    "Welsh|cy\n",
    "Xhosa|xh\n",
    "Yiddish|yi\n",
    "Yoruba|yo\n",
    "Zulu|zu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tesrimonial = TextBlob('Textblob is amazingly simple to use. What great fun!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesrimonial.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "We can break TextBlobs into words or sentences\n",
    "\n",
    "Sentence objects have the same properties and methods as TextBlobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zen = TextBlob(\"Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'beautiful': 1,\n",
       "             'better': 3,\n",
       "             'complex': 1,\n",
       "             'explicit': 1,\n",
       "             'implicit': 1,\n",
       "             'is': 3,\n",
       "             'simple': 1,\n",
       "             'than': 3,\n",
       "             'ugly': 1})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Beautiful is better than ugly.\"),\n",
       " Sentence(\"Explicit is better than implicit.\"),\n",
       " Sentence(\"Simple is better than complex.\")]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.2166666666666667, subjectivity=0.8333333333333334)\n",
      "Sentiment(polarity=0.5, subjectivity=0.5)\n",
      "Sentiment(polarity=0.06666666666666667, subjectivity=0.41904761904761906)\n"
     ]
    }
   ],
   "source": [
    "for s in zen.sentences:\n",
    "    print(s.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Usage: Overriding Models and the Blobber Class\n",
    "TextBlob允许指定想用的算法.\n",
    "\n",
    "The **textblob.sentiments** module contains two sentiment analysis implementations, **PatternAnalyzer** (based on the pattern library) and **NaiveBayesAnalyzer** (an NLTK classifier trained on a movie reviews corpus).\n",
    "\n",
    "The default implementation is **PatternAnalyzer**, but you can override the analyzer by passing another implementation into a TextBlob’s constructor.\n",
    "\n",
    "For instance, the **NaiveBayesAnalyzer** returns its result as a namedtuple of the form: **Sentiment(classification, p_pos, p_neg)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.7996209910191279, p_neg=0.2003790089808724)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"I love this library\", analyzer=NaiveBayesAnalyzer())\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizers\n",
    "The **words** and **sentences** properties are helpers that use the **textblob.tokenizers.WordTokenizer** and **textblob.tokenizers.SentenceTokenizer** classes, respectively.\n",
    "\n",
    "You can use other tokenizers, such as those provided by **NLTK**, by passing them into the **TextBlob constructor** then accessing the tokens property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['This is', 'a rather tabby', 'blob.'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TabTokenizer\n",
    "tokenizer = TabTokenizer()\n",
    "blob = TextBlob('This is\\ta rather tabby\\tblob.', tokenizer=tokenizer)\n",
    "blob.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to use the **tokenize([tokenizer])** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['A token', 'of appreciation'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "tokenizer = BlanklineTokenizer()\n",
    "blob = TextBlob(\"A token\\n\\nof appreciation\")\n",
    "blob.tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun Phrase Chunkers\n",
    "TextBlob currently has two noun phrases chunker implementations, **textblob.np_extractors.FastNPExtractor** (default, based on Shlomi Babluki’s implementation from this blog post) and **textblob.np_extractors.ConllExtractor**, which uses the CoNLL 2000 corpus to train a tagger.\n",
    "\n",
    "Use **np_extractor** to explicitly passing an instance of a noun phrase extractor to a TextBlob's constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['python', 'high-level programming language'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.np_extractors import ConllExtractor\n",
    "extractor = ConllExtractor()\n",
    "blob = TextBlob(\"Python is a high-level programming language.\",np_extractor=extractor)\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Taggers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
